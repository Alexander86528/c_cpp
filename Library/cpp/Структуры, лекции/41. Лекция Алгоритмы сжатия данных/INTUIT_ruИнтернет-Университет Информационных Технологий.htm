<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0071)http://www.intuit.ru/department/algorithms/staldata/41/staldata_41.html -->
<HTML><HEAD><TITLE>INTUIT.ru::Интернет-Университет Информационных Технологий</TITLE>
<META content="text/html; charset=windows-1251" http-equiv=Content-Type><LINK 
rel=stylesheet type=text/css 
href="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/printable.css">
<META name=GENERATOR content="MSHTML 9.00.8080.16413"></HEAD>
<BODY leftMargin=6 topMargin=6 marginwidth="6" marginheight="6">
<DIV align=left><SPAN style="COLOR: #000000; FONT-WEIGHT: bold">&nbsp;&nbsp; 
<SPAN style="FONT-SIZE: 12pt">Интернет-Университет Информационных 
Технологий</SPAN> </SPAN></DIV>&nbsp;&nbsp; <SPAN 
style="COLOR: #330066; TEXT-DECORATION: underline" 
align="rright">http://www.INTUIT.ru</SPAN> 
<TABLE border=0 cellSpacing=0 cellPadding=0 width="100%">
  <TBODY>
  <TR>
    <TD height=8 colSpan=3><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=1 height=8></TD></TR>
  <TR>
    <TD class=orang height=1 colSpan=3><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=1 height=1></TD></TR>
  <TR>
    <TD height=8 colSpan=3><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=1 height=8></TD></TR>
  <TR vAlign=top>
    <TD><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=8 height=1></TD>
    <TD><!-- content -->
      <TABLE border=0 cellSpacing=0 cellPadding=0 width="100%">
        <TBODY>
        <TR>
          <TD class=head>Структуры и алгоритмы компьютерной обработки 
        данных</TD></TR>
        <TR>
          <TD height=4><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=4></TD></TR>
        <TR>
          <TD class=orang height=1><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=1></TD></TR>
        <TR>
          <TD height=8><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=8></TD></TR>
        <TR>
          <TD><SPAN class=headsub>41. Лекция: Алгоритмы сжатия данных: версия 
            для печати и PDA</SPAN> <BR><SPAN class=rtxt>В лекции 
            рассматриваются основные понятия и алгоритмы сжатия данных, 
            приводятся примеры программной реализации алгоритма Хаффмана через 
            префиксные коды и на основе кодовых деревьев. </SPAN></TD></TR>
        <TR>
          <TD height=8><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=8></TD></TR>
        <TR>
          <TD class=orang height=1><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=1></TD></TR>
        <TR>
          <TD height=8><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=8></TD></TR>
        <TR>
          <TD><A name=sect1></A>
            <H3></H3>
            <P id=id_1><B>Цель лекции:</B> изучить основные виды и алгоритмы 
            сжатия данных и научиться решать задачи сжатия данных по методу 
            Хаффмана и с помощью кодовых деревьев.</P>
            <DIV id=mark_1 class=lecture_mark></DIV>
            <P id=id_2>Основоположником науки о сжатии информации принято 
            считать Клода Шеннона. Его теорема об оптимальном кодировании 
            показывает, к чему нужно стремиться при кодировании информации и 
            насколько та или иная информация при этом сожмется. Кроме того, им 
            были проведены опыты по эмпирической оценке избыточности английского 
            текста. Шенон предлагал людям угадывать следующую букву и оценивал 
            вероятность правильного угадывания. На основе ряда опытов он пришел 
            к выводу, что количество информации в английском тексте колеблется в 
            пределах 0,6 – 1,3 бита на символ. Несмотря на то, что результаты 
            исследований Шеннона были по-настоящему востребованы лишь 
            десятилетия спустя, трудно переоценить их значение.</P>
            <DIV id=mark_2 class=lecture_mark></DIV>
            <P id=id_3><B>Сжатие данных</B> – это процесс, обеспечивающий 
            уменьшение объема данных путем сокращения их избыточности. Сжатие 
            данных связано с компактным расположением порций данных стандартного 
            размера. Сжатие данных можно разделить на два основных типа:</P>
            <DIV id=mark_3 class=lecture_mark></DIV>
            <UL id=id_4>
              <LI><SPAN class=xml_em_italic>Сжатие без потерь (полностью 
              обратимое)</SPAN> – это метод сжатия данных, при котором ранее 
              закодированная порция данных восстанавливается после их распаковки 
              полностью без внесения изменений. Для каждого типа данных, как 
              правило, существуют свои оптимальные алгоритмы сжатия без потерь. 
              <LI><SPAN class=xml_em_italic>Сжатие с потерями</SPAN> – это метод 
              сжатия данных, при котором для обеспечения максимальной степени 
              сжатия исходного массива данных часть содержащихся в нем данных 
              отбрасывается. Для текстовых, числовых и табличных данных 
              использование программ, реализующих подобные методы сжатия, 
              является неприемлемыми. В основном такие алгоритмы применяются для 
              сжатия аудио- и видеоданных, статических изображений.</LI></UL>
            <DIV id=mark_4 class=lecture_mark></DIV>
            <P id=id_7><B>Алгоритм сжатия данных (алгоритм архивации)</B> – это 
            алгоритм, который устраняет избыточность записи данных. </P>
            <DIV id=mark_7 class=lecture_mark></DIV>
            <P id=id_8>Введем ряд определений, которые будут использоваться 
            далее в изложении материала.</P>
            <DIV id=mark_8 class=lecture_mark></DIV>
            <P id=id_9><B>Алфавит кода</B> – множество всех символов входного 
            потока. При сжатии англоязычных текстов обычно используют множество 
            из 128 ASCII кодов. При сжатии изображений множество значений 
            пиксела может содержать 2, 16, 256 или другое количество 
            элементов.</P>
            <DIV id=mark_9 class=lecture_mark></DIV>
            <P id=id_10><B>Кодовый символ</B> – наименьшая единица данных, 
            подлежащая сжатию. Обычно символ – это 1 байт, но он может быть 
            битом, тритом {0,1,2}, или чем-либо еще.</P>
            <DIV id=mark_10 class=lecture_mark></DIV>
            <P id=id_11><B>Кодовое слово</B> – это последовательность кодовых 
            символов из алфавита кода. Если все слова имеют одинаковую длину 
            (число символов), то такой код называется <SPAN 
            class=xml_em_italic>равномерным (фиксированной длины)</SPAN>, а если 
            же допускаются слова разной длины, то – <SPAN 
            class=xml_em_italic>неравномерным (переменной длины)</SPAN>.</P>
            <DIV id=mark_11 class=lecture_mark></DIV>
            <P id=id_12>Код – полное множество слов.</P>
            <DIV id=mark_12 class=lecture_mark></DIV>
            <P id=id_13><B>Токен</B> – единица данных, записываемая в сжатый 
            поток некоторым алгоритмом сжатия. Токен состоит из нескольких полей 
            фиксированной или переменной длины.</P>
            <DIV id=mark_13 class=lecture_mark></DIV>
            <P id=id_14><B>Фраза</B> – фрагмент данных, помещаемый в словарь для 
            дальнейшего использования в сжатии. </P>
            <DIV id=mark_14 class=lecture_mark></DIV>
            <P id=id_15><B>Кодирование</B> – процесс сжатия данных.</P>
            <DIV id=mark_15 class=lecture_mark></DIV>
            <P id=id_16><B>Декодирование</B> – обратный кодированию процесс, при 
            котором осуществляется восстановление данных.</P>
            <DIV id=mark_16 class=lecture_mark></DIV>
            <P id=id_17><B>Отношение сжатия</B> – одна из наиболее часто 
            используемых величин для обозначения эффективности метода сжатия. 
            <DIV id=id_18><IMG 
            alt="&#10;\textit{Отношение сжатия} = \frac{\textit{размер выходного потока}}{\textit{размер входного пособия}}&#10;" 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/ffa0388fdc0d96adbecfc832588c95c5.png" 
            width=417 height=43></DIV>Значение 0,6 означает, что данные занимают 
            60% от первоначального объема. Значения больше 1 означают, что 
            выходной поток больше входного (отрицательное сжатие, или 
            расширение).
            <P></P>
            <DIV id=mark_17 class=lecture_mark></DIV>
            <P id=id_19><B>Коэффициент сжатия</B> – величина, обратная отношению 
            сжатия. 
            <DIV id=id_20><IMG 
            alt="&#10;\textit{Коэффициент сжатия} = \frac{\textit{размер входного потока}}{\textit{размер выходного пособия}}&#10;" 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/d24d85cd427781d33b4ad28739401c28.png" 
            width=439 height=43></DIV>Значения больше 1 обозначают сжатие, а 
            значения меньше 1 – расширение.
            <P></P>
            <DIV id=mark_19 class=lecture_mark></DIV>
            <P id=id_21><B>Средняя длина кодового слова</B> – это величина, 
            которая вычисляется как взвешенная вероятностями сумма длин всех 
            кодовых слов.</P>
            <DIV id=mark_21 class=lecture_mark></DIV>
            <DIV class=example><PRE>L<SUB>cp</SUB>=p<SUB>1</SUB>L<SUB>1</SUB>+p<SUB>2</SUB>L<SUB>2</SUB>+...+p<SUB>n</SUB>L<SUB>n</SUB>,
</PRE></DIV>
            <P id=id_23>где – вероятности кодовых слов;</P>
            <DIV id=mark_23 class=lecture_mark></DIV>
            <P id=id_24><SPAN 
            class=texample>L<SUB>1</SUB>,L<SUB>2</SUB>,...,L<SUB>n</SUB></SPAN> 
            – длины кодовых слов.</P>
            <DIV id=mark_24 class=lecture_mark></DIV>
            <P id=id_26>Существуют два основных способа проведения сжатия.</P>
            <DIV id=mark_26 class=lecture_mark></DIV>
            <P id=id_27><SPAN class=xml_em_italic>Статистические методы</SPAN> – 
            методы сжатия, присваивающие коды переменной длины символам входного 
            потока, причем более короткие коды присваиваются символам или 
            группам символам, имеющим большую вероятность появления во входном 
            потоке. Лучшие статистические методы применяют кодирование 
            Хаффмана.</P>
            <DIV id=mark_27 class=lecture_mark></DIV>
            <P id=id_28><SPAN class=xml_em_italic>Словарное сжатие</SPAN> – это 
            методы сжатия, хранящие фрагменты данных в "словаре" (некоторая 
            структура данных). Если строка новых данных, поступающих на вход, 
            идентична какому-либо фрагменту, уже находящемуся в словаре, в 
            выходной поток помещается указатель на этот фрагмент. Лучшие 
            словарные методы применяют метод Зива-Лемпела.</P>
            <DIV id=mark_28 class=lecture_mark></DIV>
            <P id=id_29>Рассмотрим несколько известных алгоритмов сжатия данных 
            более подробно.</P>
            <DIV id=mark_29 class=lecture_mark></DIV><A name=sect2></A>
            <H3>Метод Хаффмана</H3>
            <P id=id_30>Этот алгоритм кодирования информации был предложен Д.А. 
            Хаффманом в 1952 году. <B>Хаффмановское кодирование (сжатие)</B> – 
            это широко используемый метод сжатия, присваивающий символам 
            алфавита коды переменной длины основываясь на вероятностях появления 
            этих символов.</P>
            <DIV id=mark_30 class=lecture_mark></DIV>
            <P id=id_31>Идея алгоритма состоит в следующем: зная вероятности 
            вхождения символов в исходный текст, можно описать процедуру 
            построения кодов переменной длины, состоящих из целого количества 
            битов. Символам с большей вероятностью присваиваются более короткие 
            коды. Таким образом, в этом методе при сжатии данных каждому символу 
            присваивается оптимальный префиксный код, основанный на вероятности 
            его появления в тексте.</P>
            <DIV id=mark_31 class=lecture_mark></DIV>
            <P id=id_32><B>Префиксный код</B> – это код, в котором никакое 
            кодовое слово не является префиксом любого другого кодового слова. 
            Эти коды имеют переменную длину.</P>
            <DIV id=mark_32 class=lecture_mark></DIV>
            <P id=id_33><B>Оптимальный префиксный код</B> – это префиксный код, 
            имеющий минимальную среднюю длину.</P>
            <DIV id=mark_33 class=lecture_mark></DIV>
            <P id=id_34><SPAN class=xml_em_italic>Алгоритм Хаффмана</SPAN> можно 
            разделить на два этапа.</P>
            <DIV id=mark_34 class=lecture_mark></DIV>
            <OL id=id_35>
              <LI>Определение вероятности появления символов в исходном тексте. 
              <P id=id_37>Первоначально необходимо прочитать исходный текст 
              полностью и подсчитать вероятности появления символов в нем 
              (иногда подсчитывают, сколько раз встречается каждый символ). Если 
              при этом учитываются все 256 символов, то не будет разницы в 
              сжатии текстового или файла иного формата.</P>
              <DIV id=mark_37 class=lecture_mark></DIV>
              <LI>Нахождение оптимального префиксного кода. 
              <P id=id_39>Далее находятся два символа <SPAN 
              class=texample>a</SPAN> и <SPAN class=texample>b</SPAN> с 
              наименьшими вероятностями появления и заменяются одним фиктивным 
              символом <SPAN class=texample>x</SPAN>, который имеет вероятность 
              появления, равную сумме вероятностей появления символов <SPAN 
              class=texample>a</SPAN> и <SPAN class=texample>b</SPAN>. Затем, 
              используя эту процедуру рекурсивно, находится оптимальный 
              префиксный код для меньшего множества символов (где символы <SPAN 
              class=texample>a</SPAN> и <SPAN class=texample>b</SPAN> заменены 
              одним символом <SPAN class=texample>x</SPAN>). Код для исходного 
              множества символов получается из кодов замещающих символов путем 
              добавления 0 или 1 перед кодом замещающего символа, и эти два 
              новых кода принимаются как коды заменяемых символов. Например, код 
              символа <SPAN class=texample>a</SPAN> будет соответствовать коду 
              <SPAN class=texample>x</SPAN> с добавленным нулем перед этим 
              кодом, а для символа <SPAN class=texample>b</SPAN> перед кодом 
              символа <SPAN class=texample>x</SPAN> будет добавлена единица.</P>
              <DIV id=mark_39 class=lecture_mark></DIV></LI></OL>
            <DIV id=mark_35 class=lecture_mark></DIV>
            <P id=id_52>Коды Хаффмана имеют уникальный префикс, что и позволяет 
            однозначно их декодировать, несмотря на их переменную длину.</P>
            <DIV id=mark_52 class=lecture_mark></DIV>
            <P id=id_53><SPAN class=xml_em_italic>Пример 1</SPAN>. Программная 
            реализация метода Хаффмана.</P>
            <DIV id=mark_53 class=lecture_mark></DIV><A></A>
            <DIV class=example><PRE>#include "stdafx.h"
#include &lt;iostream&gt;
using namespace std;

void Expectancy();
long MinK();
void SumUp();
void BuildBits();
void OutputResult(char **Result);
void Clear();

const int MaxK = 1000;
long k[MaxK + 1], a[MaxK + 1], b[MaxK + 1];
char bits[MaxK + 1][40];
char sk[MaxK + 1];
bool Free[MaxK + 1];
char *res[256];
long i, j, n, m, kj, kk1, kk2;
char str[256];

int _tmain(int argc, _TCHAR* argv[]){
  char *BinaryCode;
  Clear();
  cout &lt;&lt; "Введите строку для кодирования : ";
  cin &gt;&gt; str;
  Expectancy();
  SumUp();
  BuildBits();
  OutputResult(&amp;BinaryCode);
  cout &lt;&lt; "Закодированная строка : " &lt;&lt; endl;
  cout &lt;&lt; BinaryCode &lt;&lt; endl;
  system("pause");
  return 0;
}
//описание функции обнуления данных в массивах
void Clear(){
  for (i = 0; i &lt; MaxK + 1; i++){
    k[i] = a[i] = b[i] = 0;
    sk[i] = 0;
    Free[i] = true;
    for (j = 0; j &lt; 40; j++)
      bits[i][j] = 0;
  }
}
/*описание функции вычисления вероятности вхождения каждого символа в тексте*/
void Expectancy(){
  long *s = new long[256];
  for ( i = 0; i &lt; 256; i++)
    s[i] = 0;
  for ( n = 0; n &lt; strlen(str); n++ )
    s[str[n]]++;
  j = 0;
  for ( i = 0; i &lt; 256; i++)
    if ( s[i] != 0 ){
      j++;
      k[j] = s[i];
      sk[j] = i;
    }
  kj = j;
}
/*описание функции нахождения минимальной частоты символа в исходном тексте*/
long MinK(){
  long min;
  i = 1;
  while ( !Free[i] &amp;&amp; i &lt; MaxK) i++;
  min = k[i];
  m = i;
  for ( i = m + 1; i &lt;= kk2; i++ )
    if ( Free[i] &amp;&amp; k[i] &lt; min ){
      min = k[i];
      m = i;
    }
  Free[m] = false;
  return min;
}
//описание функции подсчета суммарной частоты символов
void SumUp(){
  long s1, s2, m1, m2;
  for ( i = 1; i &lt;= kj; i++ ){
    Free[i] = true;
    a[i] = 0;
    b[i] = 0;
  }
  kk1 = kk2 = kj;
  while (kk1 &gt; 2){
    s1 = MinK();
    m1 = m;
    s2 = MinK();
    m2 = m;
    kk2++;
    k[kk2] = s1 + s2;
    a[kk2] = m1;
    b[kk2] = m2;
    Free[kk2] = true;
    kk1--;
  }
}
//описание функции формирования префиксных кодов
void BuildBits(){
  strcpy(bits[kk2],"1");
  Free[kk2] = false;
  strcpy(bits[a[kk2]],bits[kk2]);
  strcat( bits[a[kk2]] , "0");
  strcpy(bits[b[kk2]],bits[kk2]);
  strcat( bits[b[kk2]] , "1");
  i = MinK();
  strcpy(bits[m],"0");
  Free[m] = true;
  strcpy(bits[a[m]],bits[m]);
  strcat( bits[a[m]] , "0");
  strcpy(bits[b[m]],bits[m]);
  strcat( bits[b[m]] , "1");
  for ( i = kk2 - 1; i &gt; 0; i-- )
    if ( !Free[i] ) {
      strcpy(bits[a[i]],bits[i]);
      strcat( bits[a[i]] , "0");
      strcpy(bits[b[i]],bits[i]);
      strcat( bits[b[i]] , "1");
    }
}
//описание функции вывода данных 
void OutputResult(char **Result){
  (*Result) = new char[1000];
  for (int t = 0; i &lt; 1000 ;i++)
    (*Result)[t] = 0;
  for ( i = 1; i &lt;= kj; i++ )
    res[sk[i]] = bits[i];
  for (i = 0; i &lt; strlen(str); i++)
    strcat( (*Result) , res[str[i]]);
}
</PRE><SPAN class=objectName>Листинг . </SPAN></DIV>
            <P id=id_55>Алгоритм Хаффмана универсальный, его можно применять для 
            сжатия данных любых типов, но он малоэффективен для файлов маленьких 
            размеров (за счет необходимости сохранения словаря). В настоящее 
            время данный метод практически не применяется в чистом виде, обычно 
            используется как один из этапов сжатия в более сложных схемах. Это 
            единственный алгоритм, который не увеличивает размер исходных данных 
            в худшем случае (если не считать необходимости хранить таблицу 
            перекодировки вместе с файлом).</P>
            <DIV id=mark_55 class=lecture_mark></DIV><A name=sect3></A>
            <H3>Кодовые деревья</H3>
            <P id=id_56>Рассмотрим реализацию алгоритма Хаффмана с 
            использованием кодовых деревьев.</P>
            <DIV id=mark_56 class=lecture_mark></DIV>
            <P id=id_57><B>Кодовое дерево (дерево кодирования Хаффмана, 
            Н-дерево)</B> – это бинарное дерево, у которого:</P>
            <DIV id=mark_57 class=lecture_mark></DIV>
            <UL id=id_58>
              <LI>листья помечены символами, для которых разрабатывается 
              кодировка;
              <LI>узлы (в том числе корень) помечены суммой вероятностей 
              появления всех символов, соответствующих листьям поддерева, корнем 
              которого является соответствующий узел.</LI></UL>
            <DIV id=mark_58 class=lecture_mark></DIV>
            <P id=id_61>Метод Хаффмана на входе получает таблицу частот 
            встречаемости символов в исходном тексте. Далее на основании этой 
            таблицы строится дерево кодирования Хаффмана.</P>
            <DIV id=mark_61 class=lecture_mark></DIV>
            <P id=id_62><SPAN class=xml_em_italic>Алгоритм построения дерева 
            Хаффмана.</SPAN></P>
            <DIV id=mark_62 class=lecture_mark></DIV>
            <P id=id_63>Шаг 1. Символы входного алфавита образуют список 
            свободных узлов. Каждый лист имеет вес, который может быть равен 
            либо вероятности, либо количеству вхождений символа в сжимаемый 
            текст.</P>
            <DIV id=mark_63 class=lecture_mark></DIV>
            <P id=id_64>Шаг 2. Выбираются два свободных узла дерева с 
            наименьшими весами.</P>
            <DIV id=mark_64 class=lecture_mark></DIV>
            <P id=id_65>Шаг 3. Создается их родитель с весом, равным их 
            суммарному весу.</P>
            <DIV id=mark_65 class=lecture_mark></DIV>
            <P id=id_66>Шаг 4. Родитель добавляется в список свободных узлов, а 
            двое его детей удаляются из этого списка.</P>
            <DIV id=mark_66 class=lecture_mark></DIV>
            <P id=id_67>Шаг 5. Одной дуге, выходящей из родителя, ставится в 
            соответствие бит 1, другой – бит 0.</P>
            <DIV id=mark_67 class=lecture_mark></DIV>
            <P id=id_68>Шаг 6. Повторяем шаги, начиная со второго, до тех пор, 
            пока в списке свободных узлов не останется только один свободный 
            узел. Он и будет считаться корнем дерева.</P>
            <DIV id=mark_68 class=lecture_mark></DIV>
            <P id=id_69>Существует два подхода к построению кодового дерева: от 
            корня к листьям и от листьев к корню.</P>
            <DIV id=mark_69 class=lecture_mark></DIV>
            <P id=id_70>Пример построения кодового дерева. Пусть задана исходная 
            последовательность символов:</P>
            <DIV id=mark_70 class=lecture_mark></DIV>
            <DIV class=example><PRE>aabbbbbbbbccсcdeeeee.
</PRE></DIV>
            <P id=id_72>Ее исходный объем равен 20 байт (160 бит). В 
            соответствии с приведенными на <A 
            href="http://www.intuit.ru/department/algorithms/staldata/41/staldata_41.html#image.41.1">рис. 
            41.1</A> данными (таблица вероятности появления символов, кодовое 
            дерево и таблица оптимальных префиксных кодов) закодированная 
            исходная последовательность символов будет выглядеть следующим 
            образом:</P>
            <DIV id=mark_72 class=lecture_mark></DIV>
            <DIV class=example><PRE>110111010000000011111111111111001010101010.
</PRE></DIV>
            <P id=id_74>Следовательно, ее объем будет равен 42 бита. Коэффициент 
            сжатия приближенно равен 3,8.</P>
            <DIV id=mark_74 class=lecture_mark></DIV>
            <P id=id_75 align=left><A name=image.41.1></A>
            <DIV><IMG alt="Создание оптимальных префиксных кодов" 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/41_01.png" 
            width=616 height=292></DIV><BR><B>Рис. 41.1.</B>&nbsp; Создание 
            оптимальных префиксных кодов
            <P></P>
            <DIV id=mark_75 class=lecture_mark></DIV>
            <P id=id_76>Классический алгоритм Хаффмана имеет один существенный 
            недостаток. Для восстановления содержимого сжатого текста при 
            декодировании необходимо знать таблицу частот, которую использовали 
            при кодировании. Следовательно, длина сжатого текста увеличивается 
            на длину таблицы частот, которая должна посылаться впереди данных, 
            что может свести на нет все усилия по сжатию данных. Кроме того, 
            необходимость наличия полной частотной статистики перед началом 
            собственно кодирования требует двух проходов по тексту: одного для 
            построения модели текста (таблицы частот и дерева Хаффмана), другого 
            для собственно кодирования.</P>
            <DIV id=mark_76 class=lecture_mark></DIV>
            <P id=id_77><SPAN class=xml_em_italic>Пример 2</SPAN>. Программная 
            реализация алгоритма Хаффмана с помощью кодового дерева.</P>
            <DIV id=mark_77 class=lecture_mark></DIV><A></A>
            <DIV class=example><PRE>#include "stdafx.h"
#include &lt;iostream&gt;
using namespace std;
struct sym { 
      unsigned char ch;
      float freq;     
      char code[255];
      sym *left;
      sym *right;
};
void Statistics(char *String);
sym *makeTree(sym *psym[],int k);
void makeCodes(sym *root);
void CodeHuffman(char *String,char *BinaryCode, sym *root);
void DecodeHuffman(char *BinaryCode,char *ReducedString, 
                   sym *root);
int chh;//переменная для подсчета информация из строки
int k=0;
//счётчик количества различных букв, уникальных символов
int kk=0;//счетчик количества всех знаков в файле
int kolvo[256]={0};
//инициализируем массив количества уникальных символов
sym simbols[256]={0};//инициализируем массив записей 
sym *psym[256];//инициализируем массив указателей на записи
float summir=0;//сумма частот встречаемости

int _tmain(int argc, _TCHAR* argv[]){
  char *String = new char[1000];
  char *BinaryCode = new char[1000];
  char *ReducedString = new char[1000];
  String[0] = BinaryCode[0] = ReducedString[0] = 0;
  cout &lt;&lt; "Введите строку для кодирования : ";
  cin &gt;&gt; String;
  sym *symbols = new sym[k];
  //создание динамического массива структур simbols
  sym **psum = new sym*[k];
  //создание динамического массива указателей на simbols
  Statistics(String);
  sym *root = makeTree(psym,k);
  //вызов функции создания дерева Хаффмана    
  makeCodes(root);//вызов функции получения кода
  CodeHuffman(String,BinaryCode,root);
  cout &lt;&lt; "Закодированная строка : " &lt;&lt; endl;
  cout &lt;&lt; BinaryCode &lt;&lt; endl;
  DecodeHuffman(BinaryCode,ReducedString, root);
  cout &lt;&lt; "Раскодированная строка : " &lt;&lt; endl;
  cout &lt;&lt; ReducedString &lt;&lt; endl;
  delete psum;
  delete String;
  delete BinaryCode;
  delete ReducedString;
  system("pause");
  return 0;
}
//рeкурсивная функция создания дерева Хаффмана
sym *makeTree(sym *psym[],int k) { 
  int i, j;
    sym *temp;
    temp = new sym;
    temp-&gt;freq = psym[k-1]-&gt;freq+psym[k-2]-&gt;freq;
    temp-&gt;code[0] = 0;
    temp-&gt;left = psym[k-1];
    temp-&gt;right = psym[k-2];
    if ( k == 2 )
        return temp;
    else {
    //внесение в нужное место массива элемента дерева Хаффмана
      for ( i = 0; i &lt; k; i++)
        if ( temp-&gt;freq &gt; psym[i]-&gt;freq ) {
          for( j = k - 1; j &gt; i; j--)
            psym[j] = psym[j-1]; 
            psym[i] = temp;
            break;
        } 
    }
  return makeTree(psym,k-1);
}
//рекурсивная функция кодирования дерева
void makeCodes(sym *root) { 
  if ( root-&gt;left ) {
    strcpy(root-&gt;left-&gt;code,root-&gt;code);
    strcat(root-&gt;left-&gt;code,"0");
    makeCodes(root-&gt;left);
  }
  if ( root-&gt;right ) {
    strcpy(root-&gt;right-&gt;code,root-&gt;code);
    strcat(root-&gt;right-&gt;code,"1");
    makeCodes(root-&gt;right);
  }
}
/*функция подсчета количества каждого символа и его вероятности*/
void Statistics(char *String){
  int i, j;
  //побайтно считываем строку и составляем таблицу встречаемости 
  for ( i = 0; i &lt; strlen(String); i++){
    chh = String[i];
    for ( j = 0; j &lt; 256; j++){
      if (chh==simbols[j].ch) {
        kolvo[j]++;
        kk++; 
        break;
      }
      if (simbols[j].ch==0){
        simbols[j].ch=(unsigned char)chh;
        kolvo[j]=1;
        k++; kk++;
        break;
      } 
    } 
  }
  // расчет частоты встречаемости
  for ( i = 0; i &lt; k; i++)
    simbols[i].freq = (float)kolvo[i] / kk;
  // в массив указателей заносим адреса записей
  for ( i = 0; i &lt; k; i++) 
    psym[i] = &amp;simbols[i];
  //сортировка по убыванию 
  sym tempp;
  for ( i = 1; i &lt; k; i++)
  for ( j = 0; j &lt; k - 1; j++)
    if ( simbols[j].freq &lt; simbols[j+1].freq ){
      tempp = simbols[j];
      simbols[j] = simbols[j+1];
      simbols[j+1] = tempp;
    }
  for( i=0;i&lt;k;i++)  {
    summir+=simbols[i].freq; 
    printf("Ch= %d\tFreq= %f\tPPP= %c\t\n",simbols[i].ch,
            simbols[i].freq,psym[i]-&gt;ch,i);
  }
  printf("\n Slova = %d\tSummir=%f\n",kk,summir);
}
//функция кодирования строки
void CodeHuffman(char *String,char *BinaryCode, sym *root){
  for (int  i = 0; i &lt; strlen(String); i++){
    chh = String[i];
    for (int  j = 0; j &lt; k; j++)
      if ( chh == simbols[j].ch ){
        strcat(BinaryCode,simbols[j].code);
      }
  }
}
//функция декодирования строки
void DecodeHuffman(char *BinaryCode,char *ReducedString, 
                   sym *root){
  sym *Current;// указатель в дереве
  char CurrentBit;// значение текущего бита кода
  int BitNumber;
  int CurrentSimbol;// индекс распаковываемого символа
  bool FlagOfEnd;  // флаг конца битовой последовательности
  FlagOfEnd = false;
  CurrentSimbol = 0;
  BitNumber = 0;
  Current = root;
  //пока не закончилась битовая последовательность
  while ( BitNumber != strlen(BinaryCode) ) {
    //пока не пришли в лист дерева
    while (Current-&gt;left != NULL &amp;&amp; Current-&gt;right != NULL &amp;&amp; 
           BitNumber != strlen(BinaryCode) ) {
      //читаем значение очередного бита
      CurrentBit = BinaryCode[BitNumber++];
      //бит – 0, то идем налево, бит – 1, то направо
      if ( CurrentBit == '0' ) 
        Current = Current-&gt;left;
      else 
        Current = Current-&gt;right;
    }
    //пришли в лист и формируем очередной символ
    ReducedString[CurrentSimbol++] = Current-&gt;ch;
    Current = root;
  }
  ReducedString[CurrentSimbol] = 0;
}
</PRE><SPAN class=objectName>Листинг . </SPAN></DIV>
            <P id=id_79>Для осуществления декодирования необходимо иметь кодовое 
            дерево, которое приходится хранить вместе со сжатыми данными. Это 
            приводит к некоторому незначительному увеличению объема сжатых 
            данных. Используются самые различные форматы, в которых хранят это 
            дерево. Обратим внимание на то, что узлы кодового дерева являются 
            пустыми. Иногда хранят не само дерево, а исходные данные для его 
            формирования, то есть сведения о вероятностях появления символов или 
            их количествах. При этом процесс декодирования предваряется 
            построением нового кодового дерева, которое будет таким же, как и 
            при кодировании.</P>
            <DIV id=mark_79 class=lecture_mark></DIV><A name=sect4></A>
            <H3>Ключевые термины</H3>
            <P id=id_80><B>Сжатие данных</B> – это процесс, обеспечивающий 
            уменьшение объема данных путем сокращения их избыточности.</P>
            <DIV id=mark_80 class=lecture_mark></DIV>
            <P id=id_81><B>Сжатие без потерь (полностью обратимое)</B> – это 
            метод сжатия данных, при котором ранее закодированная порция данных 
            восстанавливается после их распаковки полностью без внесения 
            изменений.</P>
            <DIV id=mark_81 class=lecture_mark></DIV>
            <P id=id_82><B>Сжатие с потерями</B> – это метод сжатия данных, при 
            котором для обеспечения максимальной степени сжатия исходного 
            массива данных часть содержащихся в нем данных отбрасывается.</P>
            <DIV id=mark_82 class=lecture_mark></DIV>
            <P id=id_83><B>Алгоритм сжатия данных (алгоритм архивации)</B> – это 
            алгоритм, который устраняет избыточность записи данных. </P>
            <DIV id=mark_83 class=lecture_mark></DIV>
            <P id=id_84><B>Алфавит кода</B> – это множество всех символов 
            входного потока.</P>
            <DIV id=mark_84 class=lecture_mark></DIV>
            <P id=id_85><B>Кодовый символ</B> – это наименьшая единица данных, 
            подлежащая сжатию.</P>
            <DIV id=mark_85 class=lecture_mark></DIV>
            <P id=id_86><B>Кодовое слово</B> – это последовательность кодовых 
            символов из алфавита кода.</P>
            <DIV id=mark_86 class=lecture_mark></DIV>
            <P id=id_87><B>Токен</B> – это единица данных, записываемая в сжатый 
            поток некоторым алгоритмом сжатия.</P>
            <DIV id=mark_87 class=lecture_mark></DIV>
            <P id=id_88><B>Фраза</B> – это фрагмент данных, помещаемый в словарь 
            для дальнейшего использования в сжатии.</P>
            <DIV id=mark_88 class=lecture_mark></DIV>
            <P id=id_89><B>Кодирование</B> – это процесс сжатия данных.</P>
            <DIV id=mark_89 class=lecture_mark></DIV>
            <P id=id_90><B>Декодирование</B> – это обратный кодированию процесс, 
            при котором осуществляется восстановление данных.</P>
            <DIV id=mark_90 class=lecture_mark></DIV>
            <P id=id_91><B>Отношение сжатия</B> – это величина для обозначения 
            эффективности метода сжатия, равная отношению размера выходного 
            потока к размеру входного потока.</P>
            <DIV id=mark_91 class=lecture_mark></DIV>
            <P id=id_92><B>Коэффициент сжатия</B> – это величина, обратная 
            отношению сжатия.</P>
            <DIV id=mark_92 class=lecture_mark></DIV>
            <P id=id_93><B>Средняя длина кодового слова</B> – это величина, 
            которая вычисляется как взвешенная вероятностями сумма длин всех 
            кодовых слов.</P>
            <DIV id=mark_93 class=lecture_mark></DIV>
            <P id=id_94><B>Статистические методы</B> – это методы сжатия, 
            присваивающие коды переменной длины символам входного потока, причем 
            более короткие коды присваиваются символам или группам символам, 
            имеющим большую вероятность появления во входном потоке.</P>
            <DIV id=mark_94 class=lecture_mark></DIV>
            <P id=id_95><B>Словарное сжатие</B> – это методы сжатия, хранящие 
            фрагменты данных в некоторой структуре данных, называемой 
            словарем.</P>
            <DIV id=mark_95 class=lecture_mark></DIV>
            <P id=id_96><B>Хаффмановское кодирование (сжатие)</B> – это метод 
            сжатия, присваивающий символам алфавита коды переменной длины 
            основываясь на вероятностях появления этих символов.</P>
            <DIV id=mark_96 class=lecture_mark></DIV>
            <P id=id_97><B>Префиксный код</B> – это код, в котором никакое 
            кодовое слово не является префиксом любого другого кодового 
            слова.</P>
            <DIV id=mark_97 class=lecture_mark></DIV>
            <P id=id_98><B>Оптимальный префиксный код</B> – это префиксный код, 
            имеющий минимальную среднюю длину.</P>
            <DIV id=mark_98 class=lecture_mark></DIV>
            <P id=id_99><B>Кодовое дерево (дерево кодирования Хаффмана, 
            Н-дерево)</B> – это бинарное дерево, у которого: листья помечены 
            символами, для которых разрабатывается кодировка; узлы (в том числе 
            корень) помечены суммой вероятностей появления всех символов, 
            соответствующих листьям поддерева, корнем которого является 
            соответствующий узел.</P>
            <DIV id=mark_99 class=lecture_mark></DIV><A name=sect5></A>
            <H3>Краткие итоги</H3>
            <OL id=id_100>
              <LI>Сжатие данных является процессом, обеспечивающим уменьшение 
              объема данных путем сокращения их избыточности.
              <LI>Сжатие данных может происходить с потерями и без потерь.
              <LI>Отношение сжатия характеризует степень сжатия данных.
              <LI>Существуют два основных способа проведения сжатия: 
              статистические методы и словарное сжатие.
              <LI>Алгоритм Хаффмана относится к статистическим методам сжатия 
              данных.
              <LI>Идея алгоритма Хаффмана состоит в следующем: зная вероятности 
              вхождения символов в исходный текст, можно описать процедуру 
              построения кодов переменной длины, состоящих из целого количества 
              битов.
              <LI>Коды Хаффмана имеют уникальный префикс, что и позволяет 
              однозначно их декодировать, несмотря на их переменную длину.
              <LI>Алгоритм Хаффмана универсальный, его можно применять для 
              сжатия данных любых типов, но он малоэффективен для файлов 
              маленьких размеров.
              <LI>Классический алгоритм Хаффмана на основе кодового дерева 
              требует хранения кодового дерева, что увеличивает его 
              трудоемкость.</LI></OL>
            <DIV id=mark_100 class=lecture_mark></DIV><A name=sect6></A>
            <H3>Лабораторная работа 41. Алгоритмы сжатия данных</H3>
            <P id=id_110><B>Цель работы:</B> изучить основные виды и алгоритмы 
            сжатия данных и научиться решать задачи сжатия данных по методу 
            Хаффмана и с помощью кодовых деревьев.</P>
            <DIV id=mark_110 class=lecture_mark></DIV>
            <P id=id_111>При выполнении лабораторной работы для каждого задания 
            требуется написать программу на языке С++, которая получает на 
            данные с клавиатуры или из входного файла, выполняет их обработку в 
            соответствии с требованиями задания и выводит результат в выходной 
            файл. Для обработки данных необходимо реализовать функции алгоритмов 
            сжатия данных по методу Хаффмана и с использованием кодовых 
            деревьев. Ограничениями на входные данные является максимальный 
            размер строковых данных, допустимый диапазон значений используемых 
            числовых типов в языке С++.</P>
            <DIV id=mark_111 class=lecture_mark></DIV>
            <P id=id_112><B>Теоретические сведения.</B></P>
            <DIV id=mark_112 class=lecture_mark></DIV>
            <P id=id_113>Ознакомьтесь с материалом лекции 41.</P>
            <DIV id=mark_113 class=lecture_mark></DIV>
            <P id=id_114><B>Задания к лабораторной работе.</B></P>
            <DIV id=mark_114 class=lecture_mark></DIV>
            <P id=id_115>Выполните приведенные ниже задания.</P>
            <DIV id=mark_115 class=lecture_mark></DIV>
            <OL id=id_116>
              <LI>На основании приведенных в лекции 41 кодов реализуйте 
              алгоритмы сжатия по методу Хаффмана через префиксные коды и на 
              основе кодовых деревьев.
              <LI>Алфавит содержит 7 букв, которые встречаются с вероятностями 
              0,4; 0,2; 0,1; 0,1; 0,1; 0,05; 0,05. Осуществите кодирование по 
              методу Хаффмана.
              <LI>Закодируйте по алгоритму Хаффмана строку с вашим именем, 
              отчеством, фамилией, датой и местом рождения (например, "Иванова 
              Наталья Николаевна, 1 января 1990 года, город Тверь"). При 
              кодировании не округляйте частоты менее, чем четыре знака после 
              запятой – сокращение точности понижает эффективность кодирования. 
              Подсчитайте коэффициент сжатия.
              <LI>При кодировании по методу Фано все сообщения записываются в 
              таблицу по степени убывания вероятности и разбиваются на две 
              группы примерно (насколько это возможно) равной вероятности. 
              Соответственно этой процедуре из корня кодового дерева исходят два 
              ребра, которым в качестве весов присваиваются полученные 
              вероятности. Двум образовавшимся вершинам приписывают кодовые 
              символы 0 и 1. Затем каждая из групп вероятностей вновь делится на 
              две подгруппы примерно равной вероятности. В соответствии с этим 
              из каждой вершины 0 и 1 исходят по два ребра с весами, равными 
              вероятностям подгрупп, а вновь образованным вершинам приписывают 
              символы 00 и 01, 10 и 11. В результате многократного повторения 
              процедуры разделения вероятностей и образования вершин приходим к 
              ситуации, когда в качестве веса, приписанного ребру бинарного 
              дерева, выступает вероятность одного из данных сообщений. В этом 
              случае вновь образованная вершина оказывается листом дерева, т.к. 
              процесс деления вероятностей для нее завершен. Задача кодирования 
              считается решенной, когда на всех ветвях кодового бинарного дерева 
              образуются листья. Закодируйте по алгоритму Фано данные текстового 
              файла.</LI></OL>
            <DIV id=mark_116 class=lecture_mark></DIV>
            <P id=id_121><B>Указания к выполнению работы.</B></P>
            <DIV id=mark_121 class=lecture_mark></DIV>
            <P id=id_122>Каждое задание необходимо решить в соответствии с 
            изученным алгоритмами сжатия данных по методу Хаффмана и с 
            использованием кодовых деревьев, реализовав программный код на языке 
            С++. Рекомендуется воспользоваться материалами лекции 41, где 
            подробно рассматриваются описание используемых в работе алгоритмов, 
            примеры их реализации на языке С++. Программу для решения каждого 
            задания необходимо разработать методом процедурной абстракции, 
            используя функции. Этапы решения сопроводить комментариями в коде. В 
            отчете следует отразить разработку и обоснование математической 
            модели решения задачи и привести примеры входных и выходных файлов, 
            полученных на этапе тестирования программ. В отчете отразить анализ 
            степени сжатия данных на примере тестовых заданий.</P>
            <DIV id=mark_122 class=lecture_mark></DIV>
            <P id=id_123>Следует реализовать каждое задание в соответствии с 
            приведенными этапами:</P>
            <DIV id=mark_123 class=lecture_mark></DIV>
            <UL id=id_124>
              <LI>изучить словесную постановку задачи, выделив при этом все виды 
              данных;
              <LI>сформулировать математическую постановку задачи;
              <LI>выбрать метод решения задачи, если это необходимо;
              <LI>разработать графическую схему алгоритма;
              <LI>записать разработанный алгоритм на языке С++;
              <LI>разработать контрольный тест к программе;
              <LI>отладить программу;
              <LI>представить отчет по работе.</LI></UL>
            <DIV id=mark_124 class=lecture_mark></DIV>
            <P id=id_133><B>Требования к отчету.</B></P>
            <DIV id=mark_133 class=lecture_mark></DIV>
            <P id=id_134>Отчет по лабораторной работе должен соответствовать 
            следующей структуре.</P>
            <DIV id=mark_134 class=lecture_mark></DIV>
            <UL id=id_135>
              <LI>Титульный лист.
              <LI>Словесная постановка задачи. В этом подразделе проводится 
              полное описание задачи. Описывается суть задачи, анализ входящих в 
              нее физических величин, область их допустимых значений, единицы их 
              измерения, возможные ограничения, анализ условий при которых 
              задача имеет решение (не имеет решения), анализ ожидаемых 
              результатов.
              <LI>Математическая модель. В этом подразделе вводятся 
              математические описания физических величин и математическое 
              описание их взаимодействий. Цель подраздела – представить решаемую 
              задачу в математической формулировке.
              <LI>Алгоритм решения задачи. В подразделе описывается разработка 
              структуры алгоритма, обосновывается абстракция данных, задача 
              разбивается на подзадачи. Схема алгоритма выполняется по ЕСПД 
              (ГОСТ 19.003-80 и ГОСТ 19.002-80).
              <LI>Листинг программы. Подраздел должен содержать текст программы 
              на языке программирования С++, реализованный в среде MS Visual 
              Studio 2010.
              <LI>Контрольный тест. Подраздел содержит наборы исходных данных и 
              полученные в ходе выполнения программы результаты.
              <LI>Выводы по лабораторной работе. 
              <LI>Ответы на контрольные вопросы.</LI></UL>
            <DIV id=mark_135 class=lecture_mark></DIV>
            <P id=id_144><B>Контрольные вопросы</B></P>
            <DIV id=mark_144 class=lecture_mark></DIV>
            <OL id=id_145>
              <LI>При кодировании каких данных можно использовать сжатие данных 
              с потерями? Ответ обоснуйте.
              <LI>В чем преимущества и недостатки статических методов и 
              словарного сжатия?
              <LI>Каким образом кодирование по алгоритму Хаффмана через 
              префиксный код гарантирует минимальную длину кода?
              <LI>За счет чего в методе Хаффмана поддерживается однозначность 
              соответствия кода кодируемому символу?
              <LI>Почему алгоритм Хаффмана малоэффективен для файлов маленьких 
              размеров?
              <LI>Выполните кодирование по методу Хаффмана через префиксный код 
              символов, которые встречаются с вероятностями 0,3; 0,2; 0,1; 0,1; 
              0,1; 0,05; 0,05; 0,04; 0,03; 0,03. Сравните полученный результат с 
              данными программной реализации.
              <LI>Докажите, что метод Хаффмана кодирует информацию без 
              потерь.</LI></OL>
            <DIV id=mark_145 class=lecture_mark></DIV></TD></TR>
        <TR>
          <TD height=8><IMG 
            src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
            width=1 height=8></TD></TR></TBODY></TABLE><!-- /content --></TD>
    <TD><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=8 height=1></TD></TR></TBODY></TABLE><!-- /bottom -->
<TABLE border=0 cellSpacing=0 cellPadding=0 width="100%">
  <TBODY>
  <TR>
    <TD class=orang height=1><IMG 
      src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/empty.gif" 
      width=1 height=1></TD></TR>
  <TR>
    <TD class=ltxt align=center>© INTUIT.ru, 2003-2010. Все права 
  защищены.</TD></TR></TBODY></TABLE><!-- /bottom -->
<SCRIPT type=text/javascript 
src="INTUIT_ruИнтернет-Университет%20Информационных%20Технологий_files/urchin.js">
</SCRIPT>

<SCRIPT 
type=text/javascript>
_uacct = "UA-3475067-1";
urchinTracker();
</SCRIPT>
</BODY></HTML>
